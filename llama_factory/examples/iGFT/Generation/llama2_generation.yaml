model_name_or_path:  meta-llama/Llama-2-13b-chat-hf

adapter_name_or_path: saves/save_folder_iteration/
template: llama2
finetuning_type: lora

# dataset
dataset: fiqa_train
cutoff_len: 1024
max_samples: 1000
overwrite_cache: true
preprocessing_num_workers: 16